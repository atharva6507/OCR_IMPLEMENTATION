{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9507652,"sourceType":"datasetVersion","datasetId":5786935}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install git+https://github.com/huggingface/transformers","metadata":{"execution":{"iopub.status.busy":"2024-09-30T17:36:56.895785Z","iopub.execute_input":"2024-09-30T17:36:56.896176Z","iopub.status.idle":"2024-09-30T17:37:50.910380Z","shell.execute_reply.started":"2024-09-30T17:36:56.896138Z","shell.execute_reply":"2024-09-30T17:37:50.909185Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers\n  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-0glqrxeh\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-0glqrxeh\n  Resolved https://github.com/huggingface/transformers to commit baa765f813942d7ba7d8e58ed2f8ca01d826afed\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (2.32.3)\nCollecting tokenizers<0.21,>=0.20 (from transformers==4.46.0.dev0)\n  Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.46.0.dev0) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.0.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.0.dev0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.0.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.0.dev0) (2024.8.30)\nDownloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.46.0.dev0-py3-none-any.whl size=9924470 sha256=50a69448bdf23f08f76901420f35871b5af7238ecd79da545784563d298e2966\n  Stored in directory: /tmp/pip-ephem-wheel-cache-wuz48won/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\nSuccessfully built transformers\nInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.2\n    Uninstalling transformers-4.44.2:\n      Successfully uninstalled transformers-4.44.2\nSuccessfully installed tokenizers-0.20.0 transformers-4.46.0.dev0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install pillow","metadata":{"execution":{"iopub.status.busy":"2024-09-30T17:37:50.912398Z","iopub.execute_input":"2024-09-30T17:37:50.912754Z","iopub.status.idle":"2024-09-30T17:38:02.276836Z","shell.execute_reply.started":"2024-09-30T17:37:50.912718Z","shell.execute_reply":"2024-09-30T17:38:02.275672Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (10.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Qwen2VLForConditionalGeneration, AutoProcessor, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-09-30T17:38:02.278156Z","iopub.execute_input":"2024-09-30T17:38:02.278498Z","iopub.status.idle":"2024-09-30T17:38:16.863753Z","shell.execute_reply.started":"2024-09-30T17:38:02.278463Z","shell.execute_reply":"2024-09-30T17:38:16.862956Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model = Qwen2VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2-VL-2B-Instruct\",\n    torch_dtype = \"auto\",\n    device_map = \"auto\"\n)\n\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")","metadata":{"execution":{"iopub.status.busy":"2024-09-30T17:38:16.865775Z","iopub.execute_input":"2024-09-30T17:38:16.866340Z","iopub.status.idle":"2024-09-30T17:39:03.904383Z","shell.execute_reply.started":"2024-09-30T17:38:16.866297Z","shell.execute_reply":"2024-09-30T17:39:03.903576Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cded4e788e445d5b4a8e179485f5f61"}},"metadata":{}},{"name":"stderr","text":"Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/56.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50b7e52b17c84b0a8f7d66e1eb90bf2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12699395085246b9ab385a7f9307876d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd54af137cac40cfa3810d8820522c2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/429M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a36081c122f744599858de21384a1962"}},"metadata":{}},{"name":"stderr","text":"`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72cd4684fe7c4e25aaabd0abc014c9c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7266ee707e4e4323b065a75166c701f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d458ccd2fa98402491b029570fa738b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d423fb8f9e834a84a792f633180c67b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aefe990329ae430eba035f54726b3c21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac35f86ab4df454fbd7ca4fb266bfb11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71d9a6d10719410db7284036fcf511f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"107da934be884d5da3db8b948d4ed847"}},"metadata":{}}]},{"cell_type":"code","source":"from PIL import Image, ImageEnhance\nimport torch\nimport requests\n\ndef compress_and_enhance_image(input_image, max_size=(1024, 1024), quality=85):\n    # Open and compress the image\n    img = input_image.copy()\n    \n    # Resize the image to fit within the max dimensions\n    img.thumbnail(max_size)\n    \n    # Convert to grayscale to enhance text contrast for OCR\n    img = img.convert(\"L\")\n    \n    # Increase contrast for better OCR accuracy\n    enhancer = ImageEnhance.Contrast(img)\n    img = enhancer.enhance(2.0)  # Adjust contrast factor as needed\n    \n    # Save or use the image in memory\n    return img\n\ndef process_image(img):\n    \n    # Load image (from your provided path or another method)\n    image = Image.open(img)\n\n    # Compress and enhance the image for OCR\n    enhanced_image = compress_and_enhance_image(image)\n\n    \n    # Existing code for processing the image with the model\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image\"\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Extract all text from image.\"\n                }\n            ]\n        }\n    ]\n\n    text_prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n\n    inputs = processor(\n        text = [text_prompt],\n        images = [enhanced_image],  # Use the enhanced and compressed image\n        padding = True,\n        return_tensors = \"pt\"\n    )\n\n    inputs = inputs.to(\"cuda\")\n\n    output_ids = model.generate(**inputs, max_new_tokens=1024)\n\n    generated_ids = [\n        output_ids[len(input_ids) : ]\n        for input_ids, output_ids in zip(inputs.input_ids, output_ids)\n    ]\n\n    output_text = processor.batch_decode(\n        generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n    )\n\n    # Output extracted text\n    return output_text\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T17:39:03.905522Z","iopub.execute_input":"2024-09-30T17:39:03.905820Z","iopub.status.idle":"2024-09-30T17:39:03.916342Z","shell.execute_reply.started":"2024-09-30T17:39:03.905787Z","shell.execute_reply":"2024-09-30T17:39:03.915365Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"process_image(\"/kaggle/input/sample/test.jpeg\")","metadata":{"execution":{"iopub.status.busy":"2024-09-30T17:39:03.917740Z","iopub.execute_input":"2024-09-30T17:39:03.918036Z","iopub.status.idle":"2024-09-30T17:39:16.621647Z","shell.execute_reply.started":"2024-09-30T17:39:03.918005Z","shell.execute_reply":"2024-09-30T17:39:16.620755Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['Here is the extracted text from the image:\\n\\nAbout - के बारे में\\nAbout me - मेरे बारे में\\nAbout us - एक्स मेरे बारे में\\nAbout them - उनके बारे में\\nAbout you - आपके बारे में\\nAbout him - उनके बारे में\\nAbout it - इसके बारे में\\nAbout whom - जिसके बारे में\\nAbout now - अभी के बारे में\\nAbout today - आज के बारे में\\nAbout life - जीवन के बारे में\\nAbout food - खाने के बारे में\\nAbout here - यहाँ के बारे में\\nAbout there - यहाँ के बारे में\\nAbout love - आंतर के बारे में']"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}